scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 10
config:
  monitor: ${task.monitor_split}/loss
  interval: epoch
  frequency: 1
